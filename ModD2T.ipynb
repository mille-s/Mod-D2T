{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMx761QrWfhvU1m1U2100PZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mille-s/Mod-D2T/blob/main/ModD2T.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hfDpapKKKcCf",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Run this cell to prepare the working folder (now setup to use FORGe-v6) and install Java 8\n",
        "from IPython.display import clear_output\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# clone Mod-D2T repo\n",
        "! git clone https://github.com/mille-s/Mod-D2T.git\n",
        "# Delete locally to avoid confusion\n",
        "! rm 'Mod-D2T/ModD2T.ipynb'\n",
        "\n",
        "# clone M-FleNS repo (generation pipeline)\n",
        "! git clone https://github.com/mille-s/M-FleNS_NLG-Pipeline.git\n",
        "# Delete locally to avoid confusion\n",
        "! rm 'M-FleNS_NLG-Pipeline/M_FleNS_pipe_v2.ipynb'\n",
        "\n",
        "# Download FORGe (text generator)\n",
        "# V2 was used for the INLG paper\n",
        "# ! gdown 1K99nCrBX2RTVMhDcPEgF0usfJYnwtE-w\n",
        "# ! unzip /content/FORGe_colab_v2.zip\n",
        "# ! rm '/content/FORGe_colab_v2.zip'\n",
        "# V4 is being tested for the Mod-D2T-GA data\n",
        "# ! gdown 196w_EtORTkR3idaXDMq0xl3pOtBrGbiE\n",
        "# ! unzip /content/FORGe_colab_v4.zip\n",
        "# ! rm '/content/FORGe_colab_v4.zip'\n",
        "# Version used for GEM (now supporting some Wikidata properties)\n",
        "# ! gdown 1gaTZVGFjtR_zBNskJXCeIJVug95aGFkf\n",
        "# ! unzip /content/FORGe_colab_v5.zip\n",
        "# ! rm '/content/FORGe_colab_v5.zip'\n",
        "# Version used for French\n",
        "! gdown 1M0yk7aLUpHiT4UfT72g-rNIPd4W8WT44\n",
        "! unzip /content/FORGe_colab_v6.zip\n",
        "! rm '/content/FORGe_colab_v6.zip'\n",
        "\n",
        "# Install parsimonious (used for parsing .str files)\n",
        "! pip install parsimonious\n",
        "\n",
        "# Clean\n",
        "clear_output()\n",
        "print('Working folder ready!\\n--------------')\n",
        "\n",
        "# Run to switch to Java 1.8 (needed for FORGe to run correctly)\n",
        "def install_java():\n",
        "  !apt-get install -y openjdk-8-jdk-headless -qq > /dev/null      #install openjdk\n",
        "  os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"     #set environment variable\n",
        "  !update-alternatives --set java /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\n",
        "  !java -version       #check java version\n",
        "install_java()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1: Convert input triples to linguistic structures\n",
        "The last cell of this block can be used to erase the input files automatically (it's a bit tedious by hand if there are many)."
      ],
      "metadata": {
        "id": "uol236MK7QVz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1. Run this cell to set general parameters\n",
        "\n",
        "language = 'FR' #@param ['EN', 'FR', 'GA']\n",
        "split = \"dev\" #@param ['dev', 'test','train']"
      ],
      "metadata": {
        "cellView": "form",
        "id": "1RU6G7pqxDQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2. Download inputs\n",
        "# For the moment, you can download the outputs of the conversion and copy the desired inputs of the same split in the str_PredArg_folder (see below).\n",
        "import os\n",
        "\n",
        "if split == 'train':\n",
        "  if os.path.exists('/content/00-PredArg-train'):\n",
        "    ! rm -r '/content/00-PredArg-train'\n",
        "  if language == 'EN':\n",
        "    ! gdown 1MQJnUWEUlELpd-mnWmsdTkJNpIPeIA48\n",
        "    ! unzip /content/00-PredArg-train.zip\n",
        "    ! rm '/content/00-PredArg-train.zip'\n",
        "  elif language == 'GA':\n",
        "    ! gdown 1bv4CjYcqkg14-Mu4TLxX94atok2LsloU\n",
        "    ! unzip /content/00-PredArg-train_GA.zip\n",
        "    ! rm '/content/00-PredArg-train_GA.zip'\n",
        "  elif language == 'FR':\n",
        "    ! gdown 1EG19aItypQcW-eyNSkioh1EPmxu29beE\n",
        "    ! unzip /content/00-PredArg-train_FR.zip\n",
        "    ! rm '/content/00-PredArg-train_FR.zip\n",
        "\n",
        "elif split == 'dev':\n",
        "  if os.path.exists('/content/00-PredArg-dev'):\n",
        "    ! rm -r '/content/00-PredArg-dev'\n",
        "  if language == 'EN':\n",
        "    ! gdown 1vm5A5WRGmnjOPrq8GsNjF3JCRGqhxigp\n",
        "    ! unzip /content/00-PredArg-dev.zip\n",
        "    ! rm '/content/00-PredArg-dev.zip\n",
        "  elif language == 'GA':\n",
        "    ! gdown 1Sg7AaDq14-BGjZYdBuJtndm8A1PmUA1A\n",
        "    ! unzip /content/00-PredArg-dev_GA.zip\n",
        "    ! rm '/content/00-PredArg-dev_GA.zip\n",
        "  elif language == 'FR':\n",
        "    ! gdown 1e0nl3X37zYkGaWHGrWThZFZzgTTEo1h4\n",
        "    ! unzip /content/00-PredArg-dev_FR.zip\n",
        "    ! rm '/content/00-PredArg-dev_FR.zip\n",
        "\n",
        "elif split == 'test':\n",
        "  if os.path.exists('/content/00-PredArg-test'):\n",
        "    ! rm -r '/content/00-PredArg-test'\n",
        "  if language == 'EN':\n",
        "    ! gdown 1qOA17TYg__89euDjQliOPrywYwgecwBc\n",
        "    ! unzip /content/00-PredArg-test.zip\n",
        "    ! rm '/content/00-PredArg-test.zip'\n",
        "  elif language == 'GA':\n",
        "    ! gdown 1w9bKDMnOn-73s8xGRTgxMfOK2YbBTWMG\n",
        "    ! unzip /content/00-PredArg-test_GA.zip\n",
        "    ! rm '/content/00-PredArg-test_GA.zip'\n",
        "  elif language == 'FR':\n",
        "    ! gdown 1J8tIUkpYhYZguqz-oVOTGAGzdq-2_euI\n",
        "    ! unzip /content/00-PredArg-test_FR.zip\n",
        "    ! rm '/content/00-PredArg-test_FR.zip\n",
        "\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "IBGuKDQhR6l2",
        "collapsed": true,
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3. Copy some PredArg structures in the input folder used for generation\n",
        "\n",
        "import glob\n",
        "import os\n",
        "\n",
        "predArg_conv_folder = ''\n",
        "if split == 'train':\n",
        "  predArg_conv_folder = '/content/00-PredArg-train'\n",
        "elif split == 'dev':\n",
        "  predArg_conv_folder = '/content/00-PredArg-dev'\n",
        "elif split == 'test':\n",
        "  predArg_conv_folder = '/content/00-PredArg-test'\n",
        "\n",
        "list_predArgPaths = glob.glob(os.path.join(predArg_conv_folder, '*.conll'))\n",
        "\n",
        "c = 0\n",
        "for predArgPath in list_predArgPaths:\n",
        "  PAfilename = os.path.split(predArgPath)[-1]\n",
        "  ! cp {predArgPath} '/content/FORGe/structures/00-PredArg/'{PAfilename}\n",
        "  c += 1\n",
        "print('Copied '+str(c)+' files.')"
      ],
      "metadata": {
        "id": "YgNIx9vHWK19",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Empty input folder to copy other inputs instead\n",
        "flush_input_folder = False #@param  {type:\"boolean\"}\n",
        "if flush_input_folder == True:\n",
        "  list_predArgPathsCC = glob.glob(os.path.join('/content/FORGe/structures/00-PredArg/', '*.conll'))\n",
        "  for predArgPathCC in list_predArgPathsCC:\n",
        "    ! rm {predArgPathCC}"
      ],
      "metadata": {
        "id": "b_iQQfvuYE3l",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2: Generate texts and intermediate representations"
      ],
      "metadata": {
        "id": "dh_llell7XZz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1. Run this cell to set parameters for generation\n",
        "import shutil\n",
        "\n",
        "# The input structure(s) of the correct type should be placed in the folder that corresponds to the first module called in the next cell\n",
        "# E.g. if one a module PredArg_... or DSynt_... is selected, the input predicate-argument structures should be placed in the structures/00-PredArg folder\n",
        "# I'll make the instructions and names clearer in a later (actually usable) version.\n",
        "\n",
        "############# Select language #############\n",
        "# GA and ES not supported for this version of the pipeline (ES will break on some structures and Morphology is missing for GA)\n",
        "# language = 'FR' #@param['EN', 'ES', 'FR', 'GA']\n",
        "\n",
        "############# Select module grouping #############\n",
        "# Group consecutive modules for the same system or call each module separately.\n",
        "# Select 'no' to get all intermediate representations ('no' for Mod-D2T), 'yes' if you're only interested in the output.\n",
        "group_modules_prm = 'no'\n",
        "\n",
        "############# Select dataset split #############\n",
        "# split = \"train\" #@param['dev', 'test','train']\n",
        "\n",
        "#######################################################################\n",
        "\n",
        "# Modules to run, with type of processing (FORGe, Model1, SimpleNLG, etc.).\n",
        "# Only FORGe is supported for this prototype version.\n",
        "# All modules are mandatory except: PredArg_Aggregation, SSynt_Aggregation, RE_Generation\n",
        "PredArg_Normalisation = 'FORGe'\n",
        "# To have an external module assigning triples to aggregate\n",
        "PredArg_AggregationMark = 'None'\n",
        "PredArg_Aggregation = 'FORGe' #@param['FORGe', 'None']\n",
        "PredArg_PoSTagging = 'FORGe'\n",
        "PredArg_CommStructuring = 'FORGe'\n",
        "DSynt_Structuring = 'FORGe'\n",
        "SSynt_Structuring = 'FORGe'\n",
        "SSynt_Aggregation = 'FORGe' #@param['FORGe', 'None']\n",
        "RE_Generation = 'FORGe' #@param['FORGe', 'None']\n",
        "DMorph_AgreementsLinearisation = 'FORGe'\n",
        "SMorph_Processing = 'FORGe'\n",
        "\n",
        "#######################################################################\n",
        "# Paths to python files\n",
        "path_MFleNS = '/content/M-FleNS_NLG-Pipeline/code/M-FleNS.py'\n",
        "path_checkOutputs = '/content/M-FleNS_NLG-Pipeline/code/M-FleNS-checkOutputs.py'\n",
        "path_concatenate = '/content/M-FleNS_NLG-Pipeline/code/concatenate_files.py'\n",
        "path_postProc = '/content/M-FleNS_NLG-Pipeline/code/postProcess.py'\n",
        "\n",
        "#######################################################################\n",
        "# Paths to FORGe/MATE folders and property files\n",
        "FORGe_input_folder = '/content/FORGe/buddy_project/struct'\n",
        "path_MATE = '/content/FORGe/buddy-patched.jar'\n",
        "path_props_resources_template = '/content/FORGe/mateColabDrive.properties'\n",
        "path_props_levels = '/content/FORGe/mateLevels.properties'\n",
        "path_props = '/content/FORGe/mate.properties'\n",
        "\n",
        "# Paths to general folders\n",
        "# The input structure(s) of the correct type should be placed in the folder that corresponds to the first module called in the next cell\n",
        "path_strs = '/content/FORGe/structures'\n",
        "str_PredArg_folder = os.path.join(path_strs, '00-PredArg')\n",
        "str_PredArgNorm_folder = os.path.join(path_strs, '01-PredArgNorm')\n",
        "str_PredArgAggMark_folder = os.path.join(path_strs, '02-PredArgAggMark')\n",
        "str_PredArgAgg_folder = os.path.join(path_strs, '03-PredArgAgg')\n",
        "str_PredArgPoS_folder = os.path.join(path_strs, '04-PredArgPoS')\n",
        "str_PredArgComm_folder = os.path.join(path_strs, '05-PredArgComm')\n",
        "str_DSynt_folder = os.path.join(path_strs, '06-DSynt')\n",
        "str_SSynt_folder = os.path.join(path_strs, '07-SSynt')\n",
        "str_SSyntAgg_folder = os.path.join(path_strs, '08-SSyntAgg')\n",
        "str_REG_folder = os.path.join(path_strs, '09-REG')\n",
        "str_DMorphLin_folder = os.path.join(path_strs, '10-DMorphLin')\n",
        "str_SMorphText_folder = os.path.join(path_strs, '11-SMorphText')\n",
        "log_folder = '/content/FORGe/log'\n",
        "if not os.path.exists(log_folder):\n",
        "  os.makedirs(log_folder)\n",
        "clean_out_str_folder = '/content/Mod-D2T/str'\n",
        "if not os.path.exists(clean_out_str_folder):\n",
        "  os.makedirs(clean_out_str_folder)\n",
        "\n",
        "def clear_folder(folder):\n",
        "  \"Function to clear whole folders.\"\n",
        "  if os.path.exists(folder) and os.path.isdir(folder):\n",
        "    try:\n",
        "      shutil.rmtree(folder)\n",
        "    except Exception as e:\n",
        "      print('Failed to delete %s. Reason: %s' % (folder, e))"
      ],
      "metadata": {
        "id": "CvKpKx825EwM",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2. Run this cell to generate the outputs (do not select \"use_existing_outputs\" unless you know what you're doing).\n",
        "use_existing_outputs = False #@param  {type:\"boolean\"}\n",
        "zip_name = 'FORGe_FRtrain_for-Mod-D2T.zip' #@param  {type:\"string\"}\n",
        "\n",
        "if use_existing_outputs == True:\n",
        "  # Alternative1. Use if you upload structures generated from another pipeline instead of using the previous\n",
        "  clear_folder('/content/FORGe/structures')\n",
        "  ! unzip '/content/'{zip_name}\n",
        "else:\n",
        "  # Alternative2. Launch generation process\n",
        "  ! python {path_MFleNS} {language} {split} {group_modules_prm} {PredArg_Normalisation} {PredArg_AggregationMark} {PredArg_Aggregation} {PredArg_PoSTagging} {PredArg_CommStructuring} {DSynt_Structuring} {SSynt_Structuring} {SSynt_Aggregation} {RE_Generation} {DMorph_AgreementsLinearisation} {SMorph_Processing} {FORGe_input_folder} {path_MATE} {path_props_resources_template} {path_props_levels} {path_props} {str_PredArg_folder} {str_PredArgNorm_folder} {str_PredArgAggMark_folder} {str_PredArgAgg_folder} {str_PredArgPoS_folder} {str_PredArgComm_folder} {str_DSynt_folder} {str_SSynt_folder} {str_SSyntAgg_folder} {str_REG_folder} {str_DMorphLin_folder} {str_SMorphText_folder} {log_folder}"
      ],
      "metadata": {
        "id": "58G3zsg7NZV_",
        "collapsed": true,
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3. (optional) Check outputs\n",
        "! python {path_checkOutputs} {str_PredArg_folder} {str_SMorphText_folder} {log_folder} {clean_out_str_folder} {language}"
      ],
      "metadata": {
        "id": "ALTWhMG072d3",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 4. Concatenate outputs of each level and copy to Mod-D2T folder\n",
        "! python {path_concatenate} {str_PredArgNorm_folder} {clean_out_str_folder} {split}\n",
        "# Not used for now ! python {path_concatenate} {str_PredArgAggMark_folder} {clean_out_str_folder} {split}\n",
        "! python {path_concatenate} {str_PredArgAgg_folder} {clean_out_str_folder} {split}\n",
        "! python {path_concatenate} {str_PredArgPoS_folder} {clean_out_str_folder} {split}\n",
        "! python {path_concatenate} {str_PredArgComm_folder} {clean_out_str_folder} {split}\n",
        "! python {path_concatenate} {str_DSynt_folder} {clean_out_str_folder} {split}\n",
        "! python {path_concatenate} {str_SSynt_folder} {clean_out_str_folder} {split}\n",
        "! python {path_concatenate} {str_SSyntAgg_folder} {clean_out_str_folder} {split}\n",
        "! python {path_concatenate} {str_REG_folder} {clean_out_str_folder} {split}\n",
        "! python {path_concatenate} {str_DMorphLin_folder} {clean_out_str_folder} {split}\n",
        "! python {path_concatenate} {str_SMorphText_folder} {clean_out_str_folder} {split}\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "GKr9_GBcUUfL",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Part 3: Clean and save the dataset, create stats and figures"
      ],
      "metadata": {
        "id": "wAeS8EZm7i7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPORTANT: str files of more than 3M lines may cause a memory exception; split very long files in files < 3M lines.\n",
        "# We'll add code to do so automatically.\n",
        "\n",
        "#@title 1. Parameters\n",
        "ROOT        = '/content/Mod-D2T/'\n",
        "SCRIPTS_DIR = os.path.join(ROOT, 'scripts')\n",
        "STR_DIR     = os.path.join(ROOT, 'str')\n",
        "STR_DIR_SPLIT = os.path.join(ROOT, 'str_split')\n",
        "CONLLU_DIR  = os.path.join(ROOT, 'conllu')\n",
        "CONLLU_DIR_SPLIT  = os.path.join(ROOT, 'conllu_split')\n",
        "EXTRACT_DIR = os.path.join(ROOT, 'extracted')\n",
        "TEX_DIR     = os.path.join(ROOT, 'tex')\n",
        "EXTRACT_ID  = 1\n",
        "EXTRACT_SEC = split\n",
        "TEXT_FILE   = '00-Text_postproc.txt'\n",
        "ENCODING    = 'utf-8'\n",
        "# Up to how many lines in a single file (to avoid reaching the 3M lines)\n",
        "LINE_LIMIT  = 2000000\n",
        "\n",
        "# sys.path.append(SCRIPTS_DIR)\n",
        "if os.path.exists('/content/Mod-D2T/str/.ipynb_checkpoints'):\n",
        "  ! rmdir '/content/Mod-D2T/str/.ipynb_checkpoints'\n",
        "if os.path.exists('/content/Mod-D2T/str/train/.ipynb_checkpoints'):\n",
        "  ! rmdir '/content/Mod-D2T/str/train/.ipynb_checkpoints'\n",
        "if os.path.exists('/content/Mod-D2T/str/dev/.ipynb_checkpoints'):\n",
        "  ! rmdir '/content/Mod-D2T/str/dev/.ipynb_checkpoints'\n",
        "if os.path.exists('/content/Mod-D2T/str/test/.ipynb_checkpoints'):\n",
        "  ! rmdir '/content/Mod-D2T/str/test/.ipynb_checkpoints'"
      ],
      "metadata": {
        "id": "4dQsigX68Seq",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2. apply post-processing to outputs\n",
        "str_out_subfolder = os.path.join(STR_DIR, split)\n",
        "! python {path_postProc} {language} {str_out_subfolder}"
      ],
      "metadata": {
        "id": "-bFse1oTN-i8",
        "collapsed": true,
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3. Split large files and check again number of texts\n",
        "import codecs\n",
        "import re\n",
        "\n",
        "def split_large_str_files(LINE_LIMIT, ROOT_path, STR_DIR_path, STR_DIR_SPLIT, TEXT_FILE_name):\n",
        "  # Get all directories in /content/Mod-D2T/str (train, dev, test)\n",
        "  str_folders = os.listdir(STR_DIR_path)\n",
        "  for str_folder in str_folders:\n",
        "    # Get list of files in folder\n",
        "    txt_file_path = os.path.join(STR_DIR_path, str_folder, TEXT_FILE_name)\n",
        "    str_files = [str_file for str_file in os.listdir(os.path.join(STR_DIR_path, str_folder)) if not str_file.startswith('00-')]\n",
        "\n",
        "    # Look for file that has the largest number of lines\n",
        "    dico_lengths_lines = {}\n",
        "    dico_lengths_strs = {}\n",
        "    max_lines = 0\n",
        "    print('Reading files\\n---------------')\n",
        "    for str_file in sorted(str_files):\n",
        "      print('  '+str_file)\n",
        "      with codecs.open(os.path.join(STR_DIR_path, str_folder, str_file), 'r', encoding=ENCODING) as f:\n",
        "        read_file = f.read()\n",
        "        lines = re.split('\\n', read_file)\n",
        "        dico_lengths_lines[str_file] = len(lines)\n",
        "        if len(lines) > max_lines:\n",
        "          max_lines = len(lines)\n",
        "        structures = re.split('\\n\\n\\n\\}\\n', read_file)\n",
        "        dico_lengths_strs[str_file] = len(structures)\n",
        "\n",
        "    # Calculate the number of files we'll need to split each file into\n",
        "    num_files = 0\n",
        "    if max_lines > LINE_LIMIT:\n",
        "      # For WebNLG, we should get max 2 files\n",
        "      # The // operator is for \"floor division\", and only gets us the integer part of the result\n",
        "      num_files = max_lines // LINE_LIMIT\n",
        "      # Round up to the integer above. The % operator gets the remainder of a division\n",
        "      if max_lines % LINE_LIMIT != 0:\n",
        "        num_files += 1\n",
        "    else:\n",
        "      num_files = 1\n",
        "\n",
        "    # print(dico_lengths_lines)\n",
        "    # print(dico_lengths_strs)\n",
        "    num_str = dico_lengths_strs['01-PredArgNorm.str']\n",
        "    # Check that all files have the same number of structures\n",
        "    for level_str in dico_lengths_strs:\n",
        "      if not dico_lengths_strs[level_str] == num_str:\n",
        "        print(f'!!!ERROR in number of structures in {level_str}. Expected {num_str}, found {dico_lengths_strs[level_str]}')\n",
        "\n",
        "    # At this point, we know if we have files to split (num_files tells us the number of files we need to not exceed the line limit).\n",
        "    if num_files > 1:\n",
        "      print(f'{max_lines} lines found in a file. Each file will be split in {num_files}.')\n",
        "      # If folder exists, remove it\n",
        "      if os.path.exists(STR_DIR_SPLIT):\n",
        "        ! rm -r {STR_DIR_SPLIT}\n",
        "      os.makedirs(STR_DIR_SPLIT)\n",
        "      # Get number of structures in each folder; we need the same number of structures for each file because they all use the same output text file\n",
        "      # This is a simplistic way of defining the size; if all very long texts are at the beginning of a file, the first file may still be too long\n",
        "      num_strs_per_file = num_str // num_files\n",
        "      # Round up to the integer above\n",
        "      if num_str % num_files != 0:\n",
        "        num_strs_per_file += 1\n",
        "\n",
        "      print('\\nSplitting files (Number of structures per file: '+str(num_strs_per_file)+')\\n---------------')\n",
        "      # Create output folders\n",
        "      x = 0\n",
        "      while x < num_files:\n",
        "        print(f'Group {x}...')\n",
        "        # Get the interval of the positions of the targeted structures\n",
        "        boundary_down =  num_strs_per_file * (x)\n",
        "        boundary_up = num_strs_per_file * (x+1)\n",
        "        print(f'Boundaries: {boundary_down} (included) to {boundary_up} (excluded).')\n",
        "        # Create new folders\n",
        "        os.makedirs(os.path.join(STR_DIR_SPLIT, 'str'+str(x), str_folder))\n",
        "        # Select desired slice in text file (same for all str files)\n",
        "        texts = codecs.open(txt_file_path, 'r', 'utf-8').readlines()[boundary_down:boundary_up]\n",
        "        # Write output text file\n",
        "        with codecs.open(os.path.join(STR_DIR_SPLIT, 'str'+str(x), str_folder, TEXT_FILE_name), 'w', 'utf-8') as fo_t:\n",
        "          fo_t.writelines(texts)\n",
        "\n",
        "        # Now slice all the files according to the established boundaries\n",
        "        for str_file in sorted(str_files):\n",
        "          print('  '+str_file)\n",
        "          with codecs.open(os.path.join(STR_DIR_path, str_folder, str_file), 'r', encoding=ENCODING) as f:\n",
        "            read_file = f.read()\n",
        "            # Select desired slice in str file\n",
        "            structures = re.split('\\n\\n\\n\\}\\n', read_file)[boundary_down:boundary_up]\n",
        "            # Write output str files\n",
        "            with codecs.open(os.path.join(STR_DIR_SPLIT, 'str'+str(x), str_folder, str_file.rsplit('.')[0]+'_'+str(x)+'.str'), 'w', 'utf-8') as fo_s:\n",
        "              fo_s.write('\\n\\n\\n}\\n'.join(structures))\n",
        "              # Write end of file for intermediate files only (the last file has the closing brackets already)\n",
        "              if x < num_files-1:\n",
        "                fo_s.write('\\n\\n\\n}\\n')\n",
        "        x += 1\n",
        "\n",
        "  return num_files\n",
        "\n",
        "number_of_files = split_large_str_files(LINE_LIMIT, ROOT, STR_DIR, STR_DIR_SPLIT, TEXT_FILE)\n",
        "\n",
        "if number_of_files == 1:\n",
        "  print('No files need to be split.')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "OI-k5dUW1Z4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 4. Convert .str files in STR_DIR to .conllu format and save to CONLLU_DIR\n",
        "if number_of_files == 1:\n",
        "  ! python3 {SCRIPTS_DIR}/convert.py -i {STR_DIR} -o {CONLLU_DIR} -t {TEXT_FILE} -e {ENCODING}\n",
        "elif number_of_files > 1:\n",
        "  for x in range(number_of_files):\n",
        "    folder_split = os.path.join(STR_DIR_SPLIT, 'str'+str(x))\n",
        "    ! python3 {SCRIPTS_DIR}/convert.py -i {folder_split} -o {CONLLU_DIR_SPLIT} -t {TEXT_FILE} -e {ENCODING}\n",
        "  # Bring the split files back together\n",
        "  if not os.path.exists(CONLLU_DIR):\n",
        "    os.makedirs(CONLLU_DIR)\n",
        "  # List the folders in CONLLU_DIR\n",
        "  traindevtest_folders = [f for f in os.listdir(CONLLU_DIR_SPLIT) if os.path.isdir(os.path.join(CONLLU_DIR_SPLIT, f))]\n",
        "  # List the files in each folder\n",
        "  for traindevtest_folder in traindevtest_folders:\n",
        "    if os.path.exists(os.path.join(CONLLU_DIR, traindevtest_folder)):\n",
        "      ! rm -r {os.path.join(CONLLU_DIR, traindevtest_folder)}\n",
        "    os.makedirs(os.path.join(CONLLU_DIR, traindevtest_folder))\n",
        "    files_in_folder = [f for f in os.listdir(os.path.join(CONLLU_DIR_SPLIT, traindevtest_folder)) if os.path.isfile(os.path.join(CONLLU_DIR_SPLIT, traindevtest_folder, f))]\n",
        "    # Get the first file for each layer\n",
        "    for file_in_folder in files_in_folder:\n",
        "      head, tail = os.path.split(file_in_folder)\n",
        "      final_filename = tail.rsplit('_', 1)[0]\n",
        "      # Create final file if extension is _0\n",
        "      if tail.rsplit('_', 1)[1] == '0.conllu':\n",
        "        with open(os.path.join(CONLLU_DIR, traindevtest_folder, final_filename+ '.conllu'), 'w') as outfile:\n",
        "          # Write the lines of the split file in the output file\n",
        "          with open(os.path.join(CONLLU_DIR_SPLIT, traindevtest_folder, file_in_folder), 'r') as infile:\n",
        "            outfile.write(infile.read())\n",
        "          # Get the number of files we need to look for, which is the total number of split files -1 because we already have the file with extension _0\n",
        "          for y in range(number_of_files-1):\n",
        "            with open(os.path.join(CONLLU_DIR_SPLIT, traindevtest_folder, final_filename+'_'+str(y+1)+'.conllu'), 'r') as infile:\n",
        "              outfile.write(infile.read())"
      ],
      "metadata": {
        "id": "dDILe0kD8c8m",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 5. (optional) Prepare files for visualising chosen example in first cell of Part 3, get stats\n",
        "# Extract structures for a text specified by its ID. They will be taken from the section specified by EXTRACT_SEC.\n",
        "! python3 {SCRIPTS_DIR}/extract.py -x {EXTRACT_ID} -i {CONLLU_DIR}/{EXTRACT_SEC} -o {EXTRACT_DIR} -e {ENCODING}\n",
        "# Export structures as LaTeX tables.\n",
        "! python3 {SCRIPTS_DIR}/export.py -i {EXTRACT_DIR} -o {TEX_DIR} -e {ENCODING}\n",
        "# Compile statistics.\n",
        "! python {SCRIPTS_DIR}/stats.py -i {CONLLU_DIR} -o {TEX_DIR} -e {ENCODING}"
      ],
      "metadata": {
        "id": "e9WYkQJZ8jsQ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Part 4: Zip and download"
      ],
      "metadata": {
        "id": "tIDfxda3QrgB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 6. Zip and download Mod-D2T data\n",
        "from google.colab import files\n",
        "zip_name_conllu = '/content/ModD2T_['+language+'].zip'\n",
        "!zip -r {zip_name_conllu} /content/Mod-D2T/conllu\n",
        "\n",
        "clear_output()\n",
        "\n",
        "files.download(zip_name_conllu)"
      ],
      "metadata": {
        "id": "V_MSikKO94lY",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 7. (optional) Zip and download tex files\n",
        "from google.colab import files\n",
        "zip_name_tex = '/content/ModD2T_['+language+']_stats-examplesTex.zip'\n",
        "!zip -r {zip_name_tex} /content/Mod-D2T/tex\n",
        "\n",
        "clear_output()\n",
        "\n",
        "files.download(zip_name_tex)"
      ],
      "metadata": {
        "id": "sz6gySPI-tss",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 8. (optional) Zip and download FORGE output folder\n",
        "from google.colab import files\n",
        "zip_name_inter = '/content/FORGe_['+language+']_['+split+']_allLevels.zip'\n",
        "!zip -r {zip_name_inter} /content/FORGe/structures\n",
        "\n",
        "clear_output()\n",
        "\n",
        "files.download(zip_name_inter)"
      ],
      "metadata": {
        "id": "5pwALyTI_MiL",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 9. (optional) Zip and download FORGe debugging\n",
        "from google.colab import files\n",
        "zip_name_log = '/content/FORGe_['+language+']_log.zip'\n",
        "!zip -r {zip_name_log} /content/FORGe/log\n",
        "\n",
        "clear_output()\n",
        "\n",
        "files.download(zip_name_log)"
      ],
      "metadata": {
        "id": "CHDkikoz-9GC",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}